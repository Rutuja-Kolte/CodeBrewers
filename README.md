# Gesture Detector

### Team name: CodeBrewers

## Team members
* Rutuja Ajay Kolte - kolterutuja1@gmail.com
* Mahek Ajay Salia - saliamahek13@gmail.com
* Reshmika Sreenath Nambiar - reshmikasnambiar@gmail.com
* Prerna Jagesia - pkjagesia@gmail.com

## Mentors
* Anuj Raghani
* Bhavya Sheth
* Owais Hetavkar
* Vedant Paranjape

## Description
The goal of our project was to train a machine learning algorithm capable of classifying images of different hand gestures (such as fists, palm, etc.) and use it for gesture detection and recognition.
* GitHub repo link: [Link to repository](https://github.com/Rutuja-Kolte/CodeBrewers)
* Drive link: [Drive link here](https://drive.google.com/drive/folders/1YxJxfa36NaUZYAGVKP1biX78SaF2loQw?usp=sharing)

## Technology stack

Tools and technologies that we learnt and used in the project.

1. Python
2. Open CV and CNN
3. Jupyter notebook
4. Machine learning

## Project Setup
1. Clone the CodeBrewers repository
2. Open Google Drive and create a folder named CodeBrewers.
3. Upload all files fro, the CodeBrewers repository on your pc to Google Drive.
4. Also add the dataset from kaggle (link given) and name it proj.zip
5. Right click on GestureDector.ipynb file in Google Drive.
6. Click on open with Google Colab.
7. Run the code.

## Usage
>Steps to run your project once its setup. If you have an app or website, list how the user can go about using it.

## Applications
1. Touchless user interface is an emerging type of technology in relation to gesture control. One type of touchless interface uses the bluetooth connectivity of a smartphone to activate a company's visitor management system. This prevents having to touch an interface during the COVID-19 pandemic.
2. Hand gesture recognition has great value in sign language recognition and sign language interpreters for the disabled.
3. In cranes, this can be used instead of remotes so that easy picking and shedding of load can be load at difficult locations.

## Future scope
The project can be linked to a Media player such as VLC and the gestures can be used to control the video like increasing or decreasing its volume or fast forwarding and rewinding the video. Also, instead of using a mouse the gestures can also be used to control your mouse pointer.  
  
Currently, the model used cannot recognise when there are no gestures detected. This functionality can be added as well.   
  
In the above project we have used only static gestures. It can be modified to include dynamic gestures (swiping your fist to the right or left, moving your finger up and down, etc.).

## Screenshots
Add a few screenshots here to give the viewer a quick idea of what your project looks like. After all, a picture speaks a thousand words.

You'll have to link the screenshots from your drive folder here.

![Screenshot alt text](https://edtimes.in/wp-content/uploads/2018/09/NikeMeme10-640x633.jpg "Here is a screenshot")

Use this template as a guide for writing your documentation. Feel free to customize and adapt it for you project.
For more Markdown syntax help, visit [here](https://www.markdownguide.org/basic-syntax/)
